{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d69d88",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-07T06:38:21.089779Z",
     "iopub.status.busy": "2021-09-07T06:38:21.084289Z",
     "iopub.status.idle": "2021-09-07T06:38:22.292461Z",
     "shell.execute_reply": "2021-09-07T06:38:22.291125Z",
     "shell.execute_reply.started": "2021-09-07T05:45:40.68619Z"
    },
    "papermill": {
     "duration": 1.239808,
     "end_time": "2021-09-07T06:38:22.292706",
     "exception": false,
     "start_time": "2021-09-07T06:38:21.052898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60301ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T06:38:22.374343Z",
     "iopub.status.busy": "2021-09-07T06:38:22.361194Z",
     "iopub.status.idle": "2021-09-07T06:38:22.411568Z",
     "shell.execute_reply": "2021-09-07T06:38:22.410926Z",
     "shell.execute_reply.started": "2021-09-07T05:45:42.003226Z"
    },
    "papermill": {
     "duration": 0.091101,
     "end_time": "2021-09-07T06:38:22.411726",
     "exception": false,
     "start_time": "2021-09-07T06:38:22.320625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap4(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train, test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['wap4'] = calc_wap4(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.std],\n",
    "        'wap2': [np.sum, np.std],\n",
    "        'wap3': [np.sum, np.std],\n",
    "        'wap4': [np.sum, np.std],\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "        'wap_balance': [np.sum, np.max],\n",
    "        'price_spread':[np.sum, np.max],\n",
    "        'price_spread2':[np.sum, np.max],\n",
    "        'bid_spread':[np.sum, np.max],\n",
    "        'ask_spread':[np.sum, np.max],\n",
    "        'total_volume':[np.sum, np.max],\n",
    "        'volume_imbalance':[np.sum, np.max],\n",
    "        \"bid_ask_spread\":[np.sum,  np.max],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32b5f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T06:38:22.461229Z",
     "iopub.status.busy": "2021-09-07T06:38:22.460511Z",
     "iopub.status.idle": "2021-09-07T07:20:28.300911Z",
     "shell.execute_reply": "2021-09-07T07:20:28.301508Z",
     "shell.execute_reply.started": "2021-09-07T05:45:42.073649Z"
    },
    "papermill": {
     "duration": 2525.869607,
     "end_time": "2021-09-07T07:20:28.301745",
     "exception": false,
     "start_time": "2021-09-07T06:38:22.432138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 42.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train, test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)\n",
    "test = get_time_stock(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71313284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:28.357272Z",
     "iopub.status.busy": "2021-09-07T07:20:28.356562Z",
     "iopub.status.idle": "2021-09-07T07:20:28.380293Z",
     "shell.execute_reply": "2021-09-07T07:20:28.379629Z",
     "shell.execute_reply.started": "2021-09-07T06:28:23.403503Z"
    },
    "papermill": {
     "duration": 0.056148,
     "end_time": "2021-09-07T07:20:28.380449",
     "exception": false,
     "start_time": "2021-09-07T07:20:28.324301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace by order sum (tau)\n",
    "train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "#train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "#test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "#train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "#test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
    "train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea64eebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:28.434175Z",
     "iopub.status.busy": "2021-09-07T07:20:28.433475Z",
     "iopub.status.idle": "2021-09-07T07:20:28.459798Z",
     "shell.execute_reply": "2021-09-07T07:20:28.459058Z",
     "shell.execute_reply.started": "2021-09-07T06:28:23.438884Z"
    },
    "papermill": {
     "duration": 0.057354,
     "end_time": "2021-09-07T07:20:28.459957",
     "exception": false,
     "start_time": "2021-09-07T07:20:28.402603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "# delta tau\n",
    "train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1019e52a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:28.513896Z",
     "iopub.status.busy": "2021-09-07T07:20:28.512984Z",
     "iopub.status.idle": "2021-09-07T07:20:28.518776Z",
     "shell.execute_reply": "2021-09-07T07:20:28.518065Z",
     "shell.execute_reply.started": "2021-09-07T06:28:23.478412Z"
    },
    "papermill": {
     "duration": 0.037147,
     "end_time": "2021-09-07T07:20:28.518914",
     "exception": false,
     "start_time": "2021-09-07T07:20:28.481767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames = [col for col in list(train.columns)\n",
    "            if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n",
    "len(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d10e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:28.577428Z",
     "iopub.status.busy": "2021-09-07T07:20:28.576522Z",
     "iopub.status.idle": "2021-09-07T07:20:30.742532Z",
     "shell.execute_reply": "2021-09-07T07:20:30.741939Z",
     "shell.execute_reply.started": "2021-09-07T06:28:23.491364Z"
    },
    "papermill": {
     "duration": 2.200798,
     "end_time": "2021-09-07T07:20:30.742714",
     "exception": false,
     "start_time": "2021-09-07T07:20:28.541916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8714e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:30.804436Z",
     "iopub.status.busy": "2021-09-07T07:20:30.800523Z",
     "iopub.status.idle": "2021-09-07T07:20:30.976509Z",
     "shell.execute_reply": "2021-09-07T07:20:30.975944Z",
     "shell.execute_reply.started": "2021-09-07T06:28:25.927171Z"
    },
    "papermill": {
     "duration": 0.208798,
     "end_time": "2021-09-07T07:20:30.976676",
     "exception": false,
     "start_time": "2021-09-07T07:20:30.767878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2b38d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:31.036707Z",
     "iopub.status.busy": "2021-09-07T07:20:31.035992Z",
     "iopub.status.idle": "2021-09-07T07:20:39.297205Z",
     "shell.execute_reply": "2021-09-07T07:20:39.297728Z",
     "shell.execute_reply.started": "2021-09-07T06:28:26.158872Z"
    },
    "papermill": {
     "duration": 8.296663,
     "end_time": "2021-09-07T07:20:39.297956",
     "exception": false,
     "start_time": "2021-09-07T07:20:31.001293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08b6e4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:39.350609Z",
     "iopub.status.busy": "2021-09-07T07:20:39.349958Z",
     "iopub.status.idle": "2021-09-07T07:20:39.462463Z",
     "shell.execute_reply": "2021-09-07T07:20:39.461900Z",
     "shell.execute_reply.started": "2021-09-07T06:28:35.47385Z"
    },
    "papermill": {
     "duration": 0.139926,
     "end_time": "2021-09-07T07:20:39.462623",
     "exception": false,
     "start_time": "2021-09-07T07:20:39.322697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c97173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:20:39.526609Z",
     "iopub.status.busy": "2021-09-07T07:20:39.521263Z",
     "iopub.status.idle": "2021-09-07T07:52:03.551648Z",
     "shell.execute_reply": "2021-09-07T07:52:03.552120Z"
    },
    "papermill": {
     "duration": 1884.064904,
     "end_time": "2021-09-07T07:52:03.552361",
     "exception": false,
     "start_time": "2021-09-07T07:20:39.487457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428698\ttraining's RMSPE: 0.198264\tvalid_1's rmse: 0.00043934\tvalid_1's RMSPE: 0.203917\n",
      "[500]\ttraining's rmse: 0.000406922\ttraining's RMSPE: 0.188193\tvalid_1's rmse: 0.000425343\tvalid_1's RMSPE: 0.19742\n",
      "[750]\ttraining's rmse: 0.000392958\ttraining's RMSPE: 0.181735\tvalid_1's rmse: 0.000416835\tvalid_1's RMSPE: 0.193471\n",
      "[1000]\ttraining's rmse: 0.000383231\ttraining's RMSPE: 0.177236\tvalid_1's rmse: 0.000412414\tvalid_1's RMSPE: 0.191419\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383231\ttraining's RMSPE: 0.177236\tvalid_1's rmse: 0.000412414\tvalid_1's RMSPE: 0.191419\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428653\ttraining's RMSPE: 0.19859\tvalid_1's rmse: 0.000440463\tvalid_1's RMSPE: 0.203012\n",
      "[500]\ttraining's rmse: 0.000406379\ttraining's RMSPE: 0.188271\tvalid_1's rmse: 0.000425018\tvalid_1's RMSPE: 0.195894\n",
      "[750]\ttraining's rmse: 0.000392668\ttraining's RMSPE: 0.181918\tvalid_1's rmse: 0.000417108\tvalid_1's RMSPE: 0.192248\n",
      "[1000]\ttraining's rmse: 0.000382831\ttraining's RMSPE: 0.177361\tvalid_1's rmse: 0.000412924\tvalid_1's RMSPE: 0.19032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382831\ttraining's RMSPE: 0.177361\tvalid_1's rmse: 0.000412924\tvalid_1's RMSPE: 0.19032\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.00042857\ttraining's RMSPE: 0.198198\tvalid_1's rmse: 0.000465999\tvalid_1's RMSPE: 0.21632\n",
      "[500]\ttraining's rmse: 0.000406477\ttraining's RMSPE: 0.187981\tvalid_1's rmse: 0.000453135\tvalid_1's RMSPE: 0.210349\n",
      "[750]\ttraining's rmse: 0.000392795\ttraining's RMSPE: 0.181653\tvalid_1's rmse: 0.000445963\tvalid_1's RMSPE: 0.207019\n",
      "[1000]\ttraining's rmse: 0.000383092\ttraining's RMSPE: 0.177166\tvalid_1's rmse: 0.000441162\tvalid_1's RMSPE: 0.204791\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383092\ttraining's RMSPE: 0.177166\tvalid_1's rmse: 0.000441162\tvalid_1's RMSPE: 0.204791\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.00042854\ttraining's RMSPE: 0.198538\tvalid_1's rmse: 0.0004457\tvalid_1's RMSPE: 0.205425\n",
      "[500]\ttraining's rmse: 0.000406238\ttraining's RMSPE: 0.188205\tvalid_1's rmse: 0.00043002\tvalid_1's RMSPE: 0.198198\n",
      "[750]\ttraining's rmse: 0.000392756\ttraining's RMSPE: 0.18196\tvalid_1's rmse: 0.000422586\tvalid_1's RMSPE: 0.194771\n",
      "[1000]\ttraining's rmse: 0.000382971\ttraining's RMSPE: 0.177426\tvalid_1's rmse: 0.000418005\tvalid_1's RMSPE: 0.19266\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382971\ttraining's RMSPE: 0.177426\tvalid_1's rmse: 0.000418005\tvalid_1's RMSPE: 0.19266\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429751\ttraining's RMSPE: 0.198779\tvalid_1's rmse: 0.000442733\tvalid_1's RMSPE: 0.205379\n",
      "[500]\ttraining's rmse: 0.000407766\ttraining's RMSPE: 0.188609\tvalid_1's rmse: 0.000428896\tvalid_1's RMSPE: 0.19896\n",
      "[750]\ttraining's rmse: 0.000394267\ttraining's RMSPE: 0.182366\tvalid_1's rmse: 0.000421757\tvalid_1's RMSPE: 0.195648\n",
      "[1000]\ttraining's rmse: 0.000383985\ttraining's RMSPE: 0.17761\tvalid_1's rmse: 0.000417711\tvalid_1's RMSPE: 0.193771\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383985\ttraining's RMSPE: 0.17761\tvalid_1's rmse: 0.000417711\tvalid_1's RMSPE: 0.193771\n",
      "Our out of folds RMSPE is 0.19466237751890056\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429995\ttraining's RMSPE: 0.198864\tvalid_1's rmse: 0.00044097\tvalid_1's RMSPE: 0.204673\n",
      "[500]\ttraining's rmse: 0.000411379\ttraining's RMSPE: 0.190254\tvalid_1's rmse: 0.00042727\tvalid_1's RMSPE: 0.198315\n",
      "[750]\ttraining's rmse: 0.000400295\ttraining's RMSPE: 0.185128\tvalid_1's rmse: 0.000419939\tvalid_1's RMSPE: 0.194912\n",
      "[1000]\ttraining's rmse: 0.000392005\ttraining's RMSPE: 0.181294\tvalid_1's rmse: 0.000414918\tvalid_1's RMSPE: 0.192582\n",
      "[1250]\ttraining's rmse: 0.000385506\ttraining's RMSPE: 0.178289\tvalid_1's rmse: 0.000411923\tvalid_1's RMSPE: 0.191191\n",
      "[1500]\ttraining's rmse: 0.000380417\ttraining's RMSPE: 0.175935\tvalid_1's rmse: 0.00040993\tvalid_1's RMSPE: 0.190266\n",
      "[1750]\ttraining's rmse: 0.000376024\ttraining's RMSPE: 0.173903\tvalid_1's rmse: 0.000408424\tvalid_1's RMSPE: 0.189567\n",
      "[2000]\ttraining's rmse: 0.000371886\ttraining's RMSPE: 0.17199\tvalid_1's rmse: 0.000407191\tvalid_1's RMSPE: 0.188995\n",
      "Early stopping, best iteration is:\n",
      "[2166]\ttraining's rmse: 0.000369275\ttraining's RMSPE: 0.170782\tvalid_1's rmse: 0.000406389\tvalid_1's RMSPE: 0.188623\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429777\ttraining's RMSPE: 0.199111\tvalid_1's rmse: 0.00043904\tvalid_1's RMSPE: 0.202357\n",
      "[500]\ttraining's rmse: 0.000410305\ttraining's RMSPE: 0.190089\tvalid_1's rmse: 0.000424362\tvalid_1's RMSPE: 0.195591\n",
      "[750]\ttraining's rmse: 0.00039904\ttraining's RMSPE: 0.184871\tvalid_1's rmse: 0.000416874\tvalid_1's RMSPE: 0.19214\n",
      "[1000]\ttraining's rmse: 0.000391081\ttraining's RMSPE: 0.181183\tvalid_1's rmse: 0.000412883\tvalid_1's RMSPE: 0.190301\n",
      "[1250]\ttraining's rmse: 0.000384919\ttraining's RMSPE: 0.178329\tvalid_1's rmse: 0.000410158\tvalid_1's RMSPE: 0.189045\n",
      "[1500]\ttraining's rmse: 0.000379509\ttraining's RMSPE: 0.175822\tvalid_1's rmse: 0.000408139\tvalid_1's RMSPE: 0.188114\n",
      "[1750]\ttraining's rmse: 0.000375125\ttraining's RMSPE: 0.173791\tvalid_1's rmse: 0.00040708\tvalid_1's RMSPE: 0.187626\n",
      "[2000]\ttraining's rmse: 0.000371023\ttraining's RMSPE: 0.17189\tvalid_1's rmse: 0.000406079\tvalid_1's RMSPE: 0.187165\n",
      "[2250]\ttraining's rmse: 0.000367333\ttraining's RMSPE: 0.170181\tvalid_1's rmse: 0.000405565\tvalid_1's RMSPE: 0.186928\n",
      "[2500]\ttraining's rmse: 0.00036372\ttraining's RMSPE: 0.168507\tvalid_1's rmse: 0.000405016\tvalid_1's RMSPE: 0.186675\n",
      "Early stopping, best iteration is:\n",
      "[2573]\ttraining's rmse: 0.000362796\ttraining's RMSPE: 0.168079\tvalid_1's rmse: 0.0004048\tvalid_1's RMSPE: 0.186575\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429437\ttraining's RMSPE: 0.198599\tvalid_1's rmse: 0.00046256\tvalid_1's RMSPE: 0.214724\n",
      "[500]\ttraining's rmse: 0.000410479\ttraining's RMSPE: 0.189832\tvalid_1's rmse: 0.000449096\tvalid_1's RMSPE: 0.208474\n",
      "[750]\ttraining's rmse: 0.000398808\ttraining's RMSPE: 0.184434\tvalid_1's rmse: 0.000442087\tvalid_1's RMSPE: 0.20522\n",
      "[1000]\ttraining's rmse: 0.000390887\ttraining's RMSPE: 0.180771\tvalid_1's rmse: 0.000437938\tvalid_1's RMSPE: 0.203294\n",
      "Early stopping, best iteration is:\n",
      "[1027]\ttraining's rmse: 0.000390115\ttraining's RMSPE: 0.180414\tvalid_1's rmse: 0.000437002\tvalid_1's RMSPE: 0.20286\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429523\ttraining's RMSPE: 0.198993\tvalid_1's rmse: 0.000445734\tvalid_1's RMSPE: 0.20544\n",
      "[500]\ttraining's rmse: 0.000410013\ttraining's RMSPE: 0.189954\tvalid_1's rmse: 0.000431096\tvalid_1's RMSPE: 0.198694\n",
      "[750]\ttraining's rmse: 0.000398929\ttraining's RMSPE: 0.184819\tvalid_1's rmse: 0.000423665\tvalid_1's RMSPE: 0.195268\n",
      "[1000]\ttraining's rmse: 0.000391057\ttraining's RMSPE: 0.181173\tvalid_1's rmse: 0.000419076\tvalid_1's RMSPE: 0.193154\n",
      "[1250]\ttraining's rmse: 0.000384792\ttraining's RMSPE: 0.17827\tvalid_1's rmse: 0.000416443\tvalid_1's RMSPE: 0.19194\n",
      "[1500]\ttraining's rmse: 0.00037957\ttraining's RMSPE: 0.17585\tvalid_1's rmse: 0.00041514\tvalid_1's RMSPE: 0.191339\n",
      "[1750]\ttraining's rmse: 0.000375113\ttraining's RMSPE: 0.173786\tvalid_1's rmse: 0.000413742\tvalid_1's RMSPE: 0.190695\n",
      "[2000]\ttraining's rmse: 0.000370972\ttraining's RMSPE: 0.171867\tvalid_1's rmse: 0.000412709\tvalid_1's RMSPE: 0.190219\n",
      "[2250]\ttraining's rmse: 0.000367304\ttraining's RMSPE: 0.170168\tvalid_1's rmse: 0.000412198\tvalid_1's RMSPE: 0.189984\n",
      "Early stopping, best iteration is:\n",
      "[2303]\ttraining's rmse: 0.000366534\ttraining's RMSPE: 0.169811\tvalid_1's rmse: 0.000411989\tvalid_1's RMSPE: 0.189887\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000430212\ttraining's RMSPE: 0.198992\tvalid_1's rmse: 0.000442301\tvalid_1's RMSPE: 0.205179\n",
      "[500]\ttraining's rmse: 0.000411635\ttraining's RMSPE: 0.190399\tvalid_1's rmse: 0.000430586\tvalid_1's RMSPE: 0.199744\n",
      "[750]\ttraining's rmse: 0.000400063\ttraining's RMSPE: 0.185047\tvalid_1's rmse: 0.000422824\tvalid_1's RMSPE: 0.196143\n",
      "[1000]\ttraining's rmse: 0.000392362\ttraining's RMSPE: 0.181484\tvalid_1's rmse: 0.000419533\tvalid_1's RMSPE: 0.194617\n",
      "[1250]\ttraining's rmse: 0.000386087\ttraining's RMSPE: 0.178582\tvalid_1's rmse: 0.000417567\tvalid_1's RMSPE: 0.193705\n",
      "Early stopping, best iteration is:\n",
      "[1322]\ttraining's rmse: 0.000384459\ttraining's RMSPE: 0.177829\tvalid_1's rmse: 0.000417279\tvalid_1's RMSPE: 0.193571\n",
      "Our out of folds RMSPE is 0.19238906021489777\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=2021\n",
    "params0 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "seed1=42\n",
    "params1 = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "seed2 = 29\n",
    "params2 = {\n",
    "        'learning_rate': 0.15,        \n",
    "        'lambda_l1': 2.154360665259325,\n",
    "        'lambda_l2': 6.711089761523827,\n",
    "        'num_leaves': 2769,\n",
    "        'min_sum_hessian_in_leaf': 20.44437160769411,\n",
    "        'feature_fraction': 0.7921473067441019,\n",
    "        'feature_fraction_bynode': 0.8083803860191322,\n",
    "        'bagging_fraction': 0.9726755660563261,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 1690,\n",
    "        'max_depth': 4,\n",
    "        'seed': seed2,\n",
    "        'feature_fraction_seed': seed2,\n",
    "        'bagging_seed': seed2,\n",
    "        'drop_seed': seed2,\n",
    "        'data_random_seed': seed2,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    } \n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params,boost=1000):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=boost,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=50,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb= train_and_evaluate_lgb(train, test,params0)\n",
    "predictions_lgb2= train_and_evaluate_lgb(train, test,params2,boost=10000)\n",
    "test['target'] = predictions_lgb\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a797e7e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:03.662646Z",
     "iopub.status.busy": "2021-09-07T07:52:03.661928Z",
     "iopub.status.idle": "2021-09-07T07:52:03.666692Z",
     "shell.execute_reply": "2021-09-07T07:52:03.667197Z"
    },
    "papermill": {
     "duration": 0.061599,
     "end_time": "2021-09-07T07:52:03.667381",
     "exception": false,
     "start_time": "2021-09-07T07:52:03.605782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428932, 248)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2d710e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:03.779079Z",
     "iopub.status.busy": "2021-09-07T07:52:03.778424Z",
     "iopub.status.idle": "2021-09-07T07:52:09.546616Z",
     "shell.execute_reply": "2021-09-07T07:52:09.545892Z"
    },
    "papermill": {
     "duration": 5.824907,
     "end_time": "2021-09-07T07:52:09.546779",
     "exception": false,
     "start_time": "2021-09-07T07:52:03.721872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f459bc25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:09.673126Z",
     "iopub.status.busy": "2021-09-07T07:52:09.667960Z",
     "iopub.status.idle": "2021-09-07T07:52:20.935861Z",
     "shell.execute_reply": "2021-09-07T07:52:20.934920Z"
    },
    "papermill": {
     "duration": 11.335611,
     "end_time": "2021-09-07T07:52:20.936020",
     "exception": false,
     "start_time": "2021-09-07T07:52:09.600409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32c44d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:21.053711Z",
     "iopub.status.busy": "2021-09-07T07:52:21.051994Z",
     "iopub.status.idle": "2021-09-07T07:52:49.324826Z",
     "shell.execute_reply": "2021-09-07T07:52:49.324252Z"
    },
    "papermill": {
     "duration": 28.335395,
     "end_time": "2021-09-07T07:52:49.324974",
     "exception": false,
     "start_time": "2021-09-07T07:52:20.989579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#colNames.remove('row_id')\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "train_nn=train[colNames].copy()\n",
    "test_nn=test[colNames].copy()\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "    train_nn[col] = qt.fit_transform(train_nn[[col]])\n",
    "    test_nn[col] = qt.transform(test_nn[[col]])    \n",
    "    qt_train.append(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27998622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:49.444341Z",
     "iopub.status.busy": "2021-09-07T07:52:49.443071Z",
     "iopub.status.idle": "2021-09-07T07:52:49.452660Z",
     "shell.execute_reply": "2021-09-07T07:52:49.452027Z"
    },
    "papermill": {
     "duration": 0.072995,
     "end_time": "2021-09-07T07:52:49.452813",
     "exception": false,
     "start_time": "2021-09-07T07:52:49.379818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_nn[['stock_id','time_id','target']]=train[['stock_id','time_id','target']]\n",
    "test_nn[['stock_id','time_id']]=test[['stock_id','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00003729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:49.572584Z",
     "iopub.status.busy": "2021-09-07T07:52:49.569379Z",
     "iopub.status.idle": "2021-09-07T07:52:51.307909Z",
     "shell.execute_reply": "2021-09-07T07:52:51.308825Z"
    },
    "papermill": {
     "duration": 1.802266,
     "end_time": "2021-09-07T07:52:51.309121",
     "exception": false,
     "start_time": "2021-09-07T07:52:49.506855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "# making agg features\n",
    "from sklearn.cluster import KMeans\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train_nn.loc[train_nn['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test_nn.loc[test_nn['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c1220d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:51.445644Z",
     "iopub.status.busy": "2021-09-07T07:52:51.444863Z",
     "iopub.status.idle": "2021-09-07T07:52:51.447048Z",
     "shell.execute_reply": "2021-09-07T07:52:51.447574Z"
    },
    "papermill": {
     "duration": 0.071277,
     "end_time": "2021-09-07T07:52:51.447766",
     "exception": false,
     "start_time": "2021-09-07T07:52:51.376489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec0ed83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:51.568231Z",
     "iopub.status.busy": "2021-09-07T07:52:51.567542Z",
     "iopub.status.idle": "2021-09-07T07:52:51.717923Z",
     "shell.execute_reply": "2021-09-07T07:52:51.717002Z"
    },
    "papermill": {
     "duration": 0.214202,
     "end_time": "2021-09-07T07:52:51.718140",
     "exception": false,
     "start_time": "2021-09-07T07:52:51.503938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08230a96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:51.842437Z",
     "iopub.status.busy": "2021-09-07T07:52:51.841713Z",
     "iopub.status.idle": "2021-09-07T07:52:57.277714Z",
     "shell.execute_reply": "2021-09-07T07:52:57.278291Z"
    },
    "papermill": {
     "duration": 5.5019,
     "end_time": "2021-09-07T07:52:57.278503",
     "exception": false,
     "start_time": "2021-09-07T07:52:51.776603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "train_nn = pd.merge(train_nn,mat1[nnn],how='left',on='time_id')\n",
    "test_nn = pd.merge(test_nn,mat2[nnn],how='left',on='time_id')\n",
    "del mat1,mat2\n",
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec095320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:57.446209Z",
     "iopub.status.busy": "2021-09-07T07:52:57.445368Z",
     "iopub.status.idle": "2021-09-07T07:52:57.465243Z",
     "shell.execute_reply": "2021-09-07T07:52:57.464673Z"
    },
    "papermill": {
     "duration": 0.095486,
     "end_time": "2021-09-07T07:52:57.465411",
     "exception": false,
     "start_time": "2021-09-07T07:52:57.369925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "\n",
    "cat_data = train_nn['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(244,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e8ae82e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:57.585463Z",
     "iopub.status.busy": "2021-09-07T07:52:57.584771Z",
     "iopub.status.idle": "2021-09-07T07:52:57.586785Z",
     "shell.execute_reply": "2021-09-07T07:52:57.587237Z"
    },
    "papermill": {
     "duration": 0.065324,
     "end_time": "2021-09-07T07:52:57.587452",
     "exception": false,
     "start_time": "2021-09-07T07:52:57.522128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70ad3db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T07:52:57.702982Z",
     "iopub.status.busy": "2021-09-07T07:52:57.702339Z",
     "iopub.status.idle": "2021-09-07T08:10:32.434629Z",
     "shell.execute_reply": "2021-09-07T08:10:32.433901Z"
    },
    "papermill": {
     "duration": 1054.791455,
     "end_time": "2021-09-07T08:10:32.434813",
     "exception": false,
     "start_time": "2021-09-07T07:52:57.643358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 4s 19ms/step - loss: 23.6953 - val_loss: 1.7192\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.9857 - val_loss: 0.5698\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.6524 - val_loss: 0.5460\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6289 - val_loss: 0.7143\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.5223 - val_loss: 0.7325\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.9121 - val_loss: 0.7280\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.6053 - val_loss: 0.5918\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.5474 - val_loss: 0.5482\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.5969 - val_loss: 0.6247\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6996 - val_loss: 0.3952\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4268 - val_loss: 0.5293\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.4212 - val_loss: 0.4298\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4442 - val_loss: 0.3448\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3713 - val_loss: 0.2358\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2307 - val_loss: 0.2692\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2302 - val_loss: 0.2331\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2391 - val_loss: 0.2683\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.4012 - val_loss: 0.2457\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2456 - val_loss: 0.2255\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2290 - val_loss: 0.2152\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2257 - val_loss: 0.2235\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2268 - val_loss: 0.2654\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2242 - val_loss: 0.2178\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2210 - val_loss: 0.2153\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2248 - val_loss: 0.2362\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2332 - val_loss: 0.2676\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2474 - val_loss: 0.2359\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2137 - val_loss: 0.2093\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2103 - val_loss: 0.2099\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2095 - val_loss: 0.2107\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2099 - val_loss: 0.2101\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2094 - val_loss: 0.2109\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2094 - val_loss: 0.2091\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2088 - val_loss: 0.2139\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2088 - val_loss: 0.2122\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2095 - val_loss: 0.2104\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2084 - val_loss: 0.2096\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2098 - val_loss: 0.2090\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2088 - val_loss: 0.2094\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2097 - val_loss: 0.2121\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2065 - val_loss: 0.2088\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2059 - val_loss: 0.2087\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2064 - val_loss: 0.2091\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2069 - val_loss: 0.2090\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2061 - val_loss: 0.2082\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2069 - val_loss: 0.2081\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2061 - val_loss: 0.2093\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2051 - val_loss: 0.2100\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2059 - val_loss: 0.2087\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2057 - val_loss: 0.2101\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2069 - val_loss: 0.2092\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2063 - val_loss: 0.2084\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2057 - val_loss: 0.2102\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2054 - val_loss: 0.2081\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2048 - val_loss: 0.2084\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2044 - val_loss: 0.2084\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2040 - val_loss: 0.2083\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2046 - val_loss: 0.2084\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2035 - val_loss: 0.2088\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2047 - val_loss: 0.2087\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2039 - val_loss: 0.2082\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2040 - val_loss: 0.2081\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2043 - val_loss: 0.2081\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2036 - val_loss: 0.2081\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2043 - val_loss: 0.2082\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2043 - val_loss: 0.2081\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2036 - val_loss: 0.2081\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2050 - val_loss: 0.2081\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2033 - val_loss: 0.2081\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2037 - val_loss: 0.2082\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2037 - val_loss: 0.2081\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2048 - val_loss: 0.2081\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2033 - val_loss: 0.2083\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2034 - val_loss: 0.2082\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2044 - val_loss: 0.2082\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2039 - val_loss: 0.2081\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2042 - val_loss: 0.2081\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2041 - val_loss: 0.2081\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2047 - val_loss: 0.2081\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2037 - val_loss: 0.2081\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2044 - val_loss: 0.2081\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2035 - val_loss: 0.2081\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2037 - val_loss: 0.2081\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2039 - val_loss: 0.2081\n",
      "Fold 1 NN: 0.20807\n",
      "CV 2/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 25.6566 - val_loss: 1.6543\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.1011 - val_loss: 0.9733\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.8101 - val_loss: 1.2899\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.1323 - val_loss: 0.8391\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.8537 - val_loss: 0.5552\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.7836 - val_loss: 0.7285\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6763 - val_loss: 1.1901\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.0350 - val_loss: 0.2397\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2926 - val_loss: 0.2799\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3044 - val_loss: 0.2815\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3052 - val_loss: 0.3467\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.3394 - val_loss: 0.2916\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3152 - val_loss: 0.3920\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4840 - val_loss: 5.6690\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 3.2251 - val_loss: 0.2610\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2268 - val_loss: 0.2277\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2206 - val_loss: 0.2262\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2161 - val_loss: 0.2270\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2171 - val_loss: 0.2225\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2150 - val_loss: 0.2215\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2140 - val_loss: 0.2215\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2124 - val_loss: 0.2267\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2149 - val_loss: 0.2186\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2127 - val_loss: 0.2189\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2127 - val_loss: 0.2197\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2132 - val_loss: 0.2180\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2124 - val_loss: 0.2201\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2131 - val_loss: 0.2214\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2119 - val_loss: 0.2199\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2117 - val_loss: 0.2246\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2146 - val_loss: 0.2200\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2139 - val_loss: 0.2181\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2126 - val_loss: 0.2202\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2071 - val_loss: 0.2153\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2055 - val_loss: 0.2147\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2058 - val_loss: 0.2145\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2057 - val_loss: 0.2157\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2059 - val_loss: 0.2157\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2061 - val_loss: 0.2136\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2052 - val_loss: 0.2136\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2063 - val_loss: 0.2154\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2054 - val_loss: 0.2147\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2060 - val_loss: 0.2165\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2055 - val_loss: 0.2153\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2051 - val_loss: 0.2130\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2060 - val_loss: 0.2158\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2054 - val_loss: 0.2130\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2060 - val_loss: 0.2159\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2082 - val_loss: 0.2135\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2044 - val_loss: 0.2181\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2058 - val_loss: 0.2129\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2046 - val_loss: 0.2169\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2049 - val_loss: 0.2176\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2064 - val_loss: 0.2132\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2040 - val_loss: 0.2148\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2042 - val_loss: 0.2161\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2055 - val_loss: 0.2147\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2043 - val_loss: 0.2205\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2023 - val_loss: 0.2137\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2017 - val_loss: 0.2136\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2136\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2009 - val_loss: 0.2116\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2020 - val_loss: 0.2138\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2013 - val_loss: 0.2138\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2020 - val_loss: 0.2134\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2023 - val_loss: 0.2137\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2014 - val_loss: 0.2135\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2019 - val_loss: 0.2135\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2117\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2009 - val_loss: 0.2126\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2005 - val_loss: 0.2128\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2005 - val_loss: 0.2125\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2004 - val_loss: 0.2128\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2007 - val_loss: 0.2123\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2010 - val_loss: 0.2129\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2014 - val_loss: 0.2131\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2005 - val_loss: 0.2128\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2007 - val_loss: 0.2128\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2014 - val_loss: 0.2126\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2004 - val_loss: 0.2129\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2008 - val_loss: 0.2128\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2010 - val_loss: 0.2130\n",
      "Fold 2 NN: 0.2116\n",
      "CV 3/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 4s 19ms/step - loss: 25.1836 - val_loss: 0.8318\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6045 - val_loss: 0.5699\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.5980 - val_loss: 0.3885\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.6727 - val_loss: 0.4867\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.5336 - val_loss: 0.5026\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4848 - val_loss: 0.4726\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.5260 - val_loss: 0.4488\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4300 - val_loss: 0.2252\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2468 - val_loss: 0.6261\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.8201 - val_loss: 0.2895\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.3098 - val_loss: 0.2348\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2461 - val_loss: 0.2219\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2338 - val_loss: 0.2568\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2368 - val_loss: 0.3503\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.7626 - val_loss: 0.3276\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2574 - val_loss: 0.2317\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2356 - val_loss: 0.2164\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2248 - val_loss: 0.2413\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2272 - val_loss: 0.2952\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2360 - val_loss: 0.2352\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2350 - val_loss: 0.2624\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2335 - val_loss: 0.2246\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2406 - val_loss: 0.2680\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2345 - val_loss: 0.2121\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2274 - val_loss: 0.2292\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2444 - val_loss: 0.2420\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2369 - val_loss: 0.2936\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2360 - val_loss: 0.2229\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3068 - val_loss: 0.2209\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2415 - val_loss: 0.2167\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2225 - val_loss: 0.2460\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2118 - val_loss: 0.2112\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2066 - val_loss: 0.2112\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2058 - val_loss: 0.2103\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2057 - val_loss: 0.2119\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2052 - val_loss: 0.2094\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2046 - val_loss: 0.2094\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2042 - val_loss: 0.2098\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2059 - val_loss: 0.2098\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2048 - val_loss: 0.2113\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2041 - val_loss: 0.2105\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2057 - val_loss: 0.2100\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2059 - val_loss: 0.2126\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2021 - val_loss: 0.2091\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2019 - val_loss: 0.2093\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2098\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2019 - val_loss: 0.2095\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2017 - val_loss: 0.2093\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2094\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2018 - val_loss: 0.2093\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2014 - val_loss: 0.2098\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2010 - val_loss: 0.2091\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2019 - val_loss: 0.2093\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2005 - val_loss: 0.2093\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2003 - val_loss: 0.2091\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2006 - val_loss: 0.2092\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2011 - val_loss: 0.2095\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2009 - val_loss: 0.2095\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2007 - val_loss: 0.2092\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2008 - val_loss: 0.2092\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2007 - val_loss: 0.2091\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2012 - val_loss: 0.2092\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2009 - val_loss: 0.2091\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1999 - val_loss: 0.2092\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2007 - val_loss: 0.2091\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2005 - val_loss: 0.2092\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2011 - val_loss: 0.2092\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2005 - val_loss: 0.2092\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2011 - val_loss: 0.2092\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2005 - val_loss: 0.2092\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1998 - val_loss: 0.2093\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2007 - val_loss: 0.2092\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2008 - val_loss: 0.2092\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2005 - val_loss: 0.2092\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1994 - val_loss: 0.2092\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2006 - val_loss: 0.2092\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2003 - val_loss: 0.2092\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2004 - val_loss: 0.2092\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.2001 - val_loss: 0.2092\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.1997 - val_loss: 0.2092\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2006 - val_loss: 0.2092\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2003 - val_loss: 0.2092\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2007 - val_loss: 0.2092\n",
      "Fold 3 NN: 0.20909\n",
      "CV 4/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 4s 18ms/step - loss: 21.0162 - val_loss: 1.3988\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.8092 - val_loss: 0.5916\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6937 - val_loss: 0.4825\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.7655 - val_loss: 0.8508\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.8862 - val_loss: 0.5065\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.6349 - val_loss: 1.6054\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 1.0557 - val_loss: 0.2387\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2608 - val_loss: 0.2433\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2572 - val_loss: 0.2786\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2551 - val_loss: 0.2766\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2777 - val_loss: 0.2326\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2827 - val_loss: 0.2890\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.4429 - val_loss: 0.2607\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2625 - val_loss: 0.2354\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2347 - val_loss: 0.3021\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2314 - val_loss: 0.2304\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2401 - val_loss: 0.2480\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2352 - val_loss: 0.2200\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2412 - val_loss: 0.2533\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2361 - val_loss: 0.3906\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2492 - val_loss: 0.2280\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2424 - val_loss: 0.2520\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2354 - val_loss: 0.2253\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2500 - val_loss: 0.2363\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2405 - val_loss: 0.2754\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2151 - val_loss: 0.2162\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2059 - val_loss: 0.2175\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2060 - val_loss: 0.2172\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2067 - val_loss: 0.2171\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2066 - val_loss: 0.2183\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2068 - val_loss: 0.2150\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2055 - val_loss: 0.2173\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.2054 - val_loss: 0.2202\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2066 - val_loss: 0.2210\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2051 - val_loss: 0.2204\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2068 - val_loss: 0.2182\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2102 - val_loss: 0.2169\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2082 - val_loss: 0.2170\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2032 - val_loss: 0.2154\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2034 - val_loss: 0.2153\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2030 - val_loss: 0.2152\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2025 - val_loss: 0.2169\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2028 - val_loss: 0.2158\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2024 - val_loss: 0.2170\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2021 - val_loss: 0.2160\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2023 - val_loss: 0.2158\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2015 - val_loss: 0.2159\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2016 - val_loss: 0.2160\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2016 - val_loss: 0.2156\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2018 - val_loss: 0.2159\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2011 - val_loss: 0.2156\n",
      "Fold 4 NN: 0.21499\n",
      "CV 5/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 32.7954 - val_loss: 0.9868\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.0166 - val_loss: 0.6044\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.5945 - val_loss: 0.4791\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.5925 - val_loss: 0.6527\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.5912 - val_loss: 0.7418\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4774 - val_loss: 0.2477\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2717 - val_loss: 0.2551\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2943 - val_loss: 0.2622\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.3032 - val_loss: 0.2543\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3138 - val_loss: 0.3060\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3080 - val_loss: 1.2261\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 5.7817 - val_loss: 0.3898\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4181 - val_loss: 0.2534\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2281 - val_loss: 0.2269\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2222 - val_loss: 0.2264\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2210 - val_loss: 0.2256\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2203 - val_loss: 0.2251\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2194 - val_loss: 0.2236\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2172 - val_loss: 0.2251\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2175 - val_loss: 0.2251\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2163 - val_loss: 0.2309\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2175 - val_loss: 0.2212\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2160 - val_loss: 0.2225\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2160 - val_loss: 0.2213\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2175 - val_loss: 0.2268\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2172 - val_loss: 0.2233\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2181 - val_loss: 0.2310\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2173 - val_loss: 0.2201\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2155 - val_loss: 0.2221\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2146 - val_loss: 0.2227\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2127 - val_loss: 0.2233\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2151 - val_loss: 0.2193\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2128 - val_loss: 0.2395\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2213 - val_loss: 0.2242\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2242 - val_loss: 0.2180\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2119 - val_loss: 0.2575\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2216 - val_loss: 0.2241\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2121 - val_loss: 0.2301\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2131 - val_loss: 0.2410\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2158 - val_loss: 0.2295\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2167 - val_loss: 0.2746\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2155 - val_loss: 0.2186\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2051 - val_loss: 0.2162\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2046 - val_loss: 0.2158\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2045 - val_loss: 0.2156\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2047 - val_loss: 0.2168\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2049 - val_loss: 0.2157\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2045 - val_loss: 0.2228\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2052 - val_loss: 0.2200\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2044 - val_loss: 0.2170\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2043 - val_loss: 0.2148\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2041 - val_loss: 0.2161\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2049 - val_loss: 0.2158\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2039 - val_loss: 0.2182\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2061 - val_loss: 0.2169\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2035 - val_loss: 0.2189\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2043 - val_loss: 0.2151\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2048 - val_loss: 0.2160\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2016 - val_loss: 0.2157\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2160\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2018 - val_loss: 0.2154\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2023 - val_loss: 0.2149\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2015 - val_loss: 0.2159\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2015 - val_loss: 0.2149\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2018 - val_loss: 0.2148\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2015 - val_loss: 0.2150\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2016 - val_loss: 0.2148\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2018 - val_loss: 0.2147\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2019 - val_loss: 0.2151\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2012 - val_loss: 0.2147\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2015 - val_loss: 0.2149\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2011 - val_loss: 0.2148\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2026 - val_loss: 0.2149\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2016 - val_loss: 0.2148\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2018 - val_loss: 0.2149\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2016 - val_loss: 0.2149\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2017 - val_loss: 0.2148\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2010 - val_loss: 0.2149\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2010 - val_loss: 0.2149\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2015 - val_loss: 0.2148\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2009 - val_loss: 0.2148\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2013 - val_loss: 0.2148\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2024 - val_loss: 0.2149\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2015 - val_loss: 0.2149\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2014 - val_loss: 0.2149\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2010 - val_loss: 0.2148\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2013 - val_loss: 0.2149\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2009 - val_loss: 0.2148\n",
      "Fold 5 NN: 0.21466\n"
     ]
    }
   ],
   "source": [
    "target_name='target'\n",
    "scores_folds = {}\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train_nn)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train_nn[features_to_consider] = train_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "test_nn[features_to_consider] = test_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "\n",
    "train_nn[pred_name] = 0\n",
    "test_nn[target_name] = 0\n",
    "test_predictions_nn = np.zeros(test_nn.shape[0])\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train_nn.loc[train_nn.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train_nn.loc[train_nn.time_id.isin(indexes), target_name]\n",
    "    X_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.006),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test_nn[features_to_consider].values)\n",
    "    #test_nn[target_name] += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    test_predictions_nn += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')\n",
    "\n",
    "# test['target'] = test_predictions_nn\n",
    "# test[['row_id', 'target']].to_csv('submission_nn.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f7aaed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T08:10:42.914232Z",
     "iopub.status.busy": "2021-09-07T08:10:42.913128Z",
     "iopub.status.idle": "2021-09-07T08:10:42.942370Z",
     "shell.execute_reply": "2021-09-07T08:10:42.941778Z"
    },
    "papermill": {
     "duration": 5.223809,
     "end_time": "2021-09-07T08:10:42.942526",
     "exception": false,
     "start_time": "2021-09-07T08:10:37.718717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE NN: 1.0 - Folds: [0.20807, 0.2116, 0.20909, 0.21499, 0.21466]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-34</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.001681\n",
       "1   0-32  0.001841\n",
       "2   0-34  0.001841"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_nn[\"row_id\"] = test_nn[\"stock_id\"].astype(str) + \"-\" + test_nn[\"time_id\"].astype(str)\n",
    "pred_lgb_m = predictions_lgb*0.615+predictions_lgb2*0.385\n",
    "#test_nn[target_name] = test_predictions_nn*0.585 + pred_lgb_m*0.415\n",
    "#20210906\n",
    "test_nn[target_name] = test_predictions_nn*0.2 + pred_lgb_m*0.8\n",
    "\n",
    "score = round(rmspe(y_true = train_nn[target_name].values, y_pred = train_nn[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "\n",
    "display(test_nn[['row_id', target_name]].head(3))\n",
    "test_nn[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "\n",
    "\n",
    "#test[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "#kmeans N=5 [0.2101, 0.21399, 0.20923, 0.21398, 0.21175]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5557.765539,
   "end_time": "2021-09-07T08:10:50.936605",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-07T06:38:13.171066",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
